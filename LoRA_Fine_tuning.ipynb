{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 207928,
     "status": "ok",
     "timestamp": 1752025918831,
     "user": {
      "displayName": "김성한",
      "userId": "01456461380721472549"
     },
     "user_tz": -540
    },
    "id": "8PT4tFJXkYW9",
    "outputId": "35ee2a53-59fa-4e8e-fa9f-0ba53863279a"
   },
   "outputs": [],
   "source": [
    "!pip install torch==2.4.0 transformers==4.45.1 datasets==3.0.1 accelerate==0.34.2 trl==0.11.1 peft==0.13.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "executionInfo": {
     "elapsed": 45394,
     "status": "error",
     "timestamp": 1752582256503,
     "user": {
      "displayName": "김성한",
      "userId": "01456461380721472549"
     },
     "user_tz": -540
    },
    "id": "da_1vgdqkbyf",
    "outputId": "aea694b0-b06c-4c2e-e566-11df5b90566f"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from peft import LoraConfig\n",
    "from trl import SFTConfig, SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241,
     "referenced_widgets": [
      "0bd8b10df7b041c69d46e5efe3a82a5f",
      "89c868b7733547eea61b7deda89a3a7f",
      "317cdcb7f76c4e868a1b137daeb4549c",
      "4ab2def64c4e4d87b3794e7eb99e561a",
      "2c6aa2d383614739b95c64d369b7356e",
      "26c91c481fc2465cb5e6b9cef7c79242",
      "e76075f1aa7440ed8464b89129a88b60",
      "e0b5ddd8dfce4a968eab1ede27b3a764",
      "584e17e2bd21488ca19469ee9f2c35c9",
      "a65ac0eaa0514e5fb2063c17687e4e37",
      "b123572811244fe9a8218497906d0708",
      "6f4e0034302048269db0743a4c10ee54",
      "eec3f04f910f4b36b554e9a23f211da4",
      "41c5501b1ea54b5087faa1e12f5fd904",
      "6288aab7edc841aeb2d48104c747f7b5",
      "0875356fb82c4e4e817f45595b138337",
      "bb01abd5121a48c083bf3e40890fbafe",
      "66db3ccdb12545b5a8fbb015b5c2d061",
      "6b90251513db4ec68d363475687d5cf3",
      "fe4cf8fcc0884ab3af17020300bdcb1f",
      "3963d840f3dc4a1d8b1a2fde4c0c2dfc",
      "228feca4c29644ecb583ed22e2d6b6ae",
      "ff72e9c2817c467cb693f97a594f8426",
      "9eaed2fef49f4c6cab17d541c3e12b5f",
      "ba2666c2aacf4e6e8d4f7220aed84597",
      "871ab6804c6241699bb10f3723525d67",
      "ccb7df4fd157431682718d7e0c7fd664",
      "faded84e41764540b62efb360ae5ce7f",
      "6ccd1e6e825443b78469acaa570aef43",
      "fa9696e9fa2447e896323bfc4b18b62f",
      "c2f631b041e84f618747fd95324a1cdf",
      "9d2df2edef8240ab946becd30557abb7",
      "1478a09eb8744ffd9e1e52908c09cc9a"
     ]
    },
    "executionInfo": {
     "elapsed": 3361,
     "status": "ok",
     "timestamp": 1752025946445,
     "user": {
      "displayName": "김성한",
      "userId": "01456461380721472549"
     },
     "user_tz": -540
    },
    "id": "fE7-q63ulume",
    "outputId": "08a1b13c-89f4-4265-fcda-9de40732ce8d"
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"iamjoon/finance_news_summarizer\", split = \"train\")\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OMDjD799l87Q"
   },
   "outputs": [],
   "source": [
    "test_ratio = 0.5\n",
    "\n",
    "data_indices = list(range(len(dataset)))\n",
    "test_size = int(len(data_indices) * test_ratio)\n",
    "\n",
    "test_data = data_indices[: test_size]\n",
    "train_data = data_indices[test_size :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1752025946556,
     "user": {
      "displayName": "김성한",
      "userId": "01456461380721472549"
     },
     "user_tz": -540
    },
    "id": "qnnnMHP2mj8x",
    "outputId": "4111fe9f-35a5-43d9-936f-11321f913558"
   },
   "outputs": [],
   "source": [
    "print(len(train_data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XIimqqePmn4s"
   },
   "outputs": [],
   "source": [
    "def format_data(sample):\n",
    "    return {\n",
    "        \"messages\" :[\n",
    "            {\"role\" : \"system\", \"content\" : sample[\"system_prompt\"]},\n",
    "            {\"role\" : \"user\", \"content\" : sample[\"user_prompt\"]},\n",
    "            {\"role\" : \"assistant\", \"content\" : str(sample[\"assistant\"])}\n",
    "        ]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BFPugjHOnHX3"
   },
   "outputs": [],
   "source": [
    "train_dataset = [format_data(dataset[i]) for i in train_data]\n",
    "test_dataset = [format_data(dataset[i]) for i in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "output_embedded_package_id": "1hoQqnNvnOhzNaPqdN1Wg-heLm0qYiqDt"
    },
    "executionInfo": {
     "elapsed": 9338,
     "status": "ok",
     "timestamp": 1752025956174,
     "user": {
      "displayName": "김성한",
      "userId": "01456461380721472549"
     },
     "user_tz": -540
    },
    "id": "4tVIVpYbncO9",
    "outputId": "687eeb40-01a4-404d-96a5-2eece1211f48"
   },
   "outputs": [],
   "source": [
    "print(train_dataset)\n",
    "print(test_dataset)\n",
    "print()\n",
    "\n",
    "print(type(train_dataset))\n",
    "print(type(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1752025956369,
     "user": {
      "displayName": "김성한",
      "userId": "01456461380721472549"
     },
     "user_tz": -540
    },
    "id": "CMm_-d-wnqKK",
    "outputId": "91ca9d90-0399-4fe0-ebd9-66c471d4f02a"
   },
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_list(train_dataset)\n",
    "test_dataset = Dataset.from_list(test_dataset)\n",
    "\n",
    "print(type(train_dataset))\n",
    "print(type(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c3pDY_DN3gJV"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 663,
     "referenced_widgets": [
      "d74b0a99771c4565bb7dc5838ba05dd3",
      "b0b34657ee6744bbb06b3eedb638edba",
      "44be2eb1a5d84650a43ea44ca1f9205a",
      "074b0c651dbc40c7950f3e261032b4d4",
      "f09f08e5209e4231aeef9822014cddfa",
      "0ca748f345864debb79dc20c1bf81c82",
      "c3625cb802fd42168b021d22c2f4c91f",
      "75489fc7faa04671bd42b992b57e3fa8",
      "44637bb4dc4e425592c5247b718601c8",
      "030972651b4247f189bf84d1ae04562b",
      "4b00ea011c964701ae65165c12501f26",
      "d1bf4f26c0bb491a8bf0bfdc699de5ea",
      "8af2af998ccc407f850076205b7e3c93",
      "132b5917238a4a0e9b35fae4403cfefc",
      "1da4b1af5cd545cab500aa1ce46b1e88",
      "ebaf9d40a0164635a5a67e0cc2fe5822",
      "d0a7e82a5bd748c5a38ea843f46f5059",
      "577f8a54826c4bcb98a4c66c7b331e00",
      "16c00d748ebd46ccbb13576a0e6a5d98",
      "ce11ee9090ff4815a9177e62698f448a",
      "419766e980334388875e98dd0d1e96a9",
      "f593d213fdcf43fe89168a12c061d3e6",
      "a47daf348a584be5a23657996523b343",
      "0a549271662e4ee6ac423edb56f8e5de",
      "09607d5cfc054797af07e9f8266ec064",
      "3222ffcc178d4cc092710f3493e5b10e",
      "16392f0e48da40da877de92f8efe2f39",
      "7959dae9f0624ad6972f5f74bd15f51c",
      "95ddc6ef42614d2a8852a3e5dd4dcc2c",
      "be0b71440d5043169b9a3282ad2ce17c",
      "afbe8797526c46d3a82eeda24805a4eb",
      "e1c38743fced4779ae6abbed2f19e708",
      "e5aeec2dd9a442ae90bb3c7c1e2d6c3b",
      "675347f40f6948f59808a0ba8b89c780",
      "ebeebd4f383d482a8493c3321706ed08",
      "90df11ce147e4b47aef4a4ffd7e1147e",
      "c1e0e69308c74b5f8edc1838a9292541",
      "28e2539b1ffb40dab6586fa27560dd19",
      "63b9867f54a646b5adb71eab2ba364e0",
      "1ebe29aef91446699d1d8bdb76bc7080",
      "ae72c5c30e3b45dfa402c696a6224f3a",
      "3c560cbe1957496aaf2ceed1ee8b58c3",
      "889c488e997f47b6bade3deeca1de5b1",
      "af78c5355d5b445ba2bb917f04c56e06",
      "c581228c3bab4b1782659595c9ec9a88",
      "3b651d4c0204428abc77319db823e3e7",
      "844876d2f4e647caa084d6cdc0f5132f",
      "bf1515026de240479153d07ce3266d8d",
      "6f50f81961e948b8b8a8a097abc5eae4",
      "f8bd955a113f47bbbeff6e2162871754",
      "9bd592f6b49f4cee9dedfeb88a89575f",
      "d74b630e61a14a7586aef92349e0b220",
      "92fb20eaf24949c78ccbd1584d42671a",
      "ab48200bd6a647e0b810a444fc7b5c50",
      "4ac1943df0224cb0b5a95b870e70c9dd",
      "422955ef958843dbbca4beaf9f49099f",
      "d3321b239cee4112a4a88e9757b4e79f",
      "74ca4c4f2adf4f8f969f6510015c52c2",
      "f9b8deb86aaa4d33962603a810d3f9eb",
      "28fc3980ffd54a709db8f2befc98739c",
      "8e72f7684ee549bf8441cd0f83bb1b37",
      "fd76a8e9442640a9b3546032528bae2b",
      "896531c947ca45c1a561accb2857546b",
      "b71d13fd2abc418aa23787ff3aa6f925",
      "0978e0310cbd4c64827d083f4026c8e4",
      "6c3ac9bf36a1436c8fec92096a1ac87a",
      "2a6b73cdcc2f4c829c4d66dd0943cb55",
      "edc84fda316c4383897653d486288086",
      "44937c2cd3c147ecb2cce7d3652bac88",
      "198b909a348441fc9909b83a4ffd3ba2",
      "5d09c0b6205c4c27b8965348baa024bc",
      "00f113e91efb42759b6b5656bc86b1bd",
      "253924c5bfda4e18a2ec1533e5d83673",
      "ddc3c5e6ba44422e9469e9577dc08452",
      "62dbac3327e343ecb7acd87ebbe8fa2a",
      "902243c92d23420bac59d0da464b1f8a",
      "4dc35d1a605a48ba87b55caee31e4442",
      "b897d53412d24813afbfc143bb42241d",
      "b96e634ea6cc4feea32dc08844385350",
      "a4552c7e57404cd188b380912a8b10f2",
      "dbe77fb5df954e8ab7299438fce4977b",
      "1f26c52be5c94665bbf72cb086ce5807",
      "9b0478f7b0e54122b292b0a069da9622",
      "9ce0596ce34b4589ad19c15573cfb4d0",
      "b1cd9f06d6dd446f8bd04810129f94dc",
      "0451ec1aa2ee487b8d85a33b2c0f0eed",
      "51f9502c634d478da4a83245d4ba38c1",
      "1c89c93c9ccb40cc99c97e3979859d48"
     ]
    },
    "executionInfo": {
     "elapsed": 147142,
     "status": "error",
     "timestamp": 1752026103571,
     "user": {
      "displayName": "김성한",
      "userId": "01456461380721472549"
     },
     "user_tz": -540
    },
    "id": "JVfX1UKtn6so",
    "outputId": "232b65e9-70d5-4b37-e440-f41dcd28201f"
   },
   "outputs": [],
   "source": [
    "model_id = \"NCSOFT/Llama-VARCO-8B-Instruct\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id,\n",
    "                                             device_map = \"auto\"\n",
    "                                             torch_dtype = torch.bfloat16)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5zb2ek-ztZK_"
   },
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    lora_alpha = 32,\n",
    "    lora_dropout = 0.1,\n",
    "    r = 8,\n",
    "    bias = \"none\",\n",
    "    target_modules = ['q_proj', 'v_proj'],\n",
    "    task_type = \"CAUSAL_LM\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A4P3zJXKuMJj"
   },
   "outputs": [],
   "source": [
    "args = SFTConfig(\n",
    "    output_dir = \"llama3-8b-summarizer-ko\",\n",
    "    num_train_epochs = 3,\n",
    "    per_device_train_batch_size = 2,\n",
    "    gradient_accumulation_steps = 2,\n",
    "    gradient_checkpointing = True,\n",
    "    optim = \"adamw_torch_fused\",\n",
    "    logging_steps = 10,\n",
    "    save_strategy = \"steps\",\n",
    "    save_steps = 50,\n",
    "    bf16 = True,\n",
    "    learning_rate = 1e-4,\n",
    "    max_grad_norm = 0.3,\n",
    "    warmup_ratio = 0.03,\n",
    "    lr_scheduler_type = \"constant\",\n",
    "    push_to_hub = False,\n",
    "    remove_unused_columns = False,\n",
    "    dataset_kwargs = {\"skip_prepare_dataset\" : True},\n",
    "    report_to = None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dsfGIq8lvRk2"
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    new_batch = {\n",
    "        \"input_ids\" : [],\n",
    "        \"attention_mask\" : [],\n",
    "        \"labels\" : []\n",
    "    }\n",
    "\n",
    "    for example in batch:\n",
    "        message = example[\"messages\"]\n",
    "\n",
    "        prompt = \"<|begin_of_text|>\"\n",
    "        for msg in message:\n",
    "            role = msg[\"role\"]\n",
    "            content = msg[\"content\"].strip()\n",
    "            prompt += f\"<|start_header_id|>{role}<|end_header_id|>\\n{content}<|eot_id|>\"\n",
    "\n",
    "        text = prompt.strip()\n",
    "\n",
    "        tokenized = tokenizer(text,\n",
    "                              truncation = True,\n",
    "                              padding = False,\n",
    "                              max_length = max_seq_length,\n",
    "                              return_tensors = None)\n",
    "\n",
    "        input_ids = tokenized[\"input_ids\"]\n",
    "        attention_mask = tokenized[\"attention_mask\"]\n",
    "        labels = [-100] * len(input_ids)\n",
    "\n",
    "        assistant_token = \"<|start_header_id|>assistant<|end_header_id|>\\n\"\n",
    "        assistant_tokens = tokenizer.encode(assistant_token, add_special_tokens = False)\n",
    "\n",
    "        eot_token = \"<|eot_id|>\"\n",
    "        eot_tokens = tokenizer.encode(eot_token, add_special_tokens = False)\n",
    "\n",
    "        i = 0\n",
    "        while i <= len(input_ids) - len(assistant_tokens):\n",
    "            if input_ids[i : i + len(assistant_tokens)] == assistant_tokens:\n",
    "                start = i + len(assistant_tokens)\n",
    "                end = start\n",
    "\n",
    "                while end <= len(input_ids) - len(eot_tokens):\n",
    "                    if input_ids[end : end + len(eot_tokens)] == eot_tokens:\n",
    "                        break\n",
    "                    end += 1\n",
    "\n",
    "                for j in range(start, end):\n",
    "                    labels[j] = input_ids[j]\n",
    "                for j in range(end, end + len(eot_tokens)):\n",
    "                    labels[j] = input_ids[j]\n",
    "                break\n",
    "\n",
    "            i += 1\n",
    "\n",
    "        new_batch[\"input_ids\"].append(input_ids)\n",
    "        new_batch[\"attention_mask\"].append(attention_mask)\n",
    "        new_batch['labels'].append(labels)\n",
    "\n",
    "    max_length = max(len(ids) for ids in new_batch[\"input_ids\"])\n",
    "    for i in range(len(new_batch[\"input_ids\"])):\n",
    "        pad = max_length - len(new_batch[\"input_ids\"][i])\n",
    "        new_batch[\"input_ids\"].extend([tokenizer.pad_token_id] * pad)\n",
    "        new_batch[\"attention_mask\"].extend([0] * pad)\n",
    "        new_batch[\"labels\"].extend([-100] * pad)\n",
    "\n",
    "    for k in new_batch:\n",
    "        new_batch[k] = torch.tensor(new_batch[k])\n",
    "\n",
    "    return new_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ma5nFrR03KR5"
   },
   "outputs": [],
   "source": [
    "max_seq_length = 8192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WDjn0dSl0HWd"
   },
   "outputs": [],
   "source": [
    "example = train_dataset[0]\n",
    "batch = collate_fn([example])\n",
    "\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LHW5P68H0gaI"
   },
   "outputs": [],
   "source": [
    "print(batch['input_ids'][0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q_69kddH03Ps"
   },
   "outputs": [],
   "source": [
    "print(batch[\"labels\"][0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bjY_8bFT090w"
   },
   "outputs": [],
   "source": [
    "decoded_text = tokenizer.decode(batch[\"input_ids\"][0].tolist(),\n",
    "                                skip_special_tokens = False,\n",
    "                                cleanup_tokenization_spaces = False)\n",
    "\n",
    "print(decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xYLnvSZZ1jBT"
   },
   "outputs": [],
   "source": [
    "label_ids = [token_id for token_id in batch[\"labels\"][0].tolist() if token_id != -100]\n",
    "decoded_label = tokenizer.decode(label_ids,\n",
    "                                 skip_special_tokens = False,\n",
    "                                 cleanup_tokenization_spaces = False)\n",
    "\n",
    "decoded_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kz0SmoOP2Llf"
   },
   "outputs": [],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    args = args,\n",
    "    train_dataset = train_dataset,\n",
    "    data_collator = collate_fn,\n",
    "    peft_config = peft_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sYGZbuZT26py"
   },
   "outputs": [],
   "source": [
    "trainer.train()\n",
    "\n",
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HJwsVB0k7Ni3"
   },
   "outputs": [],
   "source": [
    "prompt_list = []\n",
    "labels_list = []\n",
    "\n",
    "for message in test_dataset['messages']:\n",
    "    text = tokenizer.apply_chat_template(message, tokenize = False, add_generation_prompt = False)\n",
    "    input = text.split('<|start_header_id|>assistant<|end_header_id|>\\n')[0] + '<|start_header_id|>assistant<|end_header_id|>\\n')\n",
    "    label = text.split('<|start_header_id|>assistant<|end_header_id|>\\n')[1].split('<|eot_id|>')[0])\n",
    "    prompt_list.append(input)\n",
    "    labels_list.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VfuDiP488NLB"
   },
   "outputs": [],
   "source": [
    "fine_model = AutoModelForCausalLm.from_pretrained(\"llama3-8b-summarizer-ko/checkpoint-372\", device_map = \"auto\", torch_dtype = torch.bfloat16)\n",
    "pipe = pipeline(\"text-generation\", model = \"llama3-8b-summarizer-ko/checkpoint-372\", tokenizer = tokenizer)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOGer/6QzBIeziG1VzuukjK",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
