{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "DOXbdfpO2Woy"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from transformers import BertTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "s1zOpK1Q5kr9",
    "outputId": "526da9cc-e0d1-40e0-bfa3-9da6cce78e14"
   },
   "outputs": [],
   "source": [
    "!wget https://korquad.github.io/dataset/KorQuAD_v1.0_train.json -O KorQuAD_v1.0_train.json\n",
    "!wget https://korquad.github.io/dataset/KorQuAD_v1.0_dev.json -O KorQuAD_v1.0_dev.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "RQGWSvuajDrB"
   },
   "outputs": [],
   "source": [
    "def read_squad(path):\n",
    "  path = Path(path)\n",
    "\n",
    "  with open(path, 'rb') as f:\n",
    "    squad_dict = json.load(f)\n",
    "\n",
    "  contexts = []\n",
    "  questions = []\n",
    "  answers = []\n",
    "\n",
    "  for group in squad_dict['data']:\n",
    "    for passage in group['paragraphs']:\n",
    "      context = passage['context']\n",
    "\n",
    "      for qa in passage['qas']:\n",
    "        question = qa['question']\n",
    "\n",
    "        for answer in qa['answers']:\n",
    "          contexts.append(context)\n",
    "          questions.append(question)\n",
    "          answers.append(answer)\n",
    "\n",
    "  return contexts, questions, answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "l8nedpXKkQSA"
   },
   "outputs": [],
   "source": [
    "train_contexts, train_questions, train_answers = read_squad('KorQuAD_v1.0_train.json')\n",
    "test_contexts, test_questions, test_answers = read_squad('KorQuAD_v1.0_dev.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "_Y7vJ21QkgE8",
    "outputId": "7b5ee771-69ef-4521-9ced-8d92da6a2fe3"
   },
   "outputs": [],
   "source": [
    "print('훈련 데이터')\n",
    "print('본문 개수 :', len(train_contexts))\n",
    "print('질문 개수 :', len(train_questions))\n",
    "print('답변 개수 :', len(train_answers))\n",
    "print('-' * 100)\n",
    "\n",
    "print('테스트 데이터')\n",
    "print('본문 개수 :', len(test_contexts))\n",
    "print('질문 개수 :', len(test_questions))\n",
    "print('답변 개수 :', len(test_answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "9kY6Zq_1lPAm",
    "outputId": "d9dfbd6b-532e-4593-e6b9-b0feea0a4c6a"
   },
   "outputs": [],
   "source": [
    "print(train_contexts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "1YUStXAflV4o",
    "outputId": "3e06fba8-f184-4633-e7c2-8ae9d97dcb19"
   },
   "outputs": [],
   "source": [
    "print(train_questions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "sYy1Zpn-lXNW",
    "outputId": "7a07ee66-3141-487f-bdf5-91e8ad14e25b"
   },
   "outputs": [],
   "source": [
    "print(train_answers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fy68sCLMlZqY"
   },
   "outputs": [],
   "source": [
    "def add_end_idx(answers, contexts):\n",
    "  for answer, context in zip(answers, contexts):\n",
    "    answer['text'] = answer['text'].rstrip()\n",
    "\n",
    "    gold_text = answer['text']\n",
    "    start_idx = answer['answer_start']\n",
    "    end_idx = start_idx + len(gold_text)\n",
    "\n",
    "    assert context[start_idx:end_idx] == gold_text, 'Calculate Error'\n",
    "\n",
    "    answer['answer_end'] = end_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xeZFcbU9mH_f"
   },
   "outputs": [],
   "source": [
    "add_end_idx(train_answers, train_contexts)\n",
    "add_end_idx(test_answers, test_contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oHLB7rAgmRAf"
   },
   "outputs": [],
   "source": [
    "print(train_answers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eLZh9Gfpmf8x"
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained('klue/bert-base')\n",
    "\n",
    "train_encoding = tokenizer(train_contexts, train_questions, truncation = True, padding = True, max_length = 256)\n",
    "test_encoding = tokenizer(test_contexts, test_questions, truncation = True, padding = True, max_length = 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "noGCTgAim7FK"
   },
   "outputs": [],
   "source": [
    "print('첫 번째 샘플의 토큰화 결과 :', train_encoding[0].tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U3f16n3LnK2m"
   },
   "outputs": [],
   "source": [
    "print('첫 번째 샘플의 길이 :', len(train_encoding[0].tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Bj67rG_nQR8"
   },
   "outputs": [],
   "source": [
    "print('첫 번째 샘플의 어텐션 마스크 :', train_encoding[0].attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oOKXqdjynZEG"
   },
   "outputs": [],
   "source": [
    "def add_token_position(encodings, answers):\n",
    "  start_positions = []\n",
    "  end_positions = []\n",
    "  deleting_list = []\n",
    "\n",
    "  for i in tqdm(range(len(answers))):\n",
    "    start_positions.append(encodings.char_to_token(i, answers[i]['answer_start']))\n",
    "    end_positions.append(encodings.char_to_token(i, answers[i]['answer_end'] - 1))\n",
    "\n",
    "    # 시작 인덱스가 비정상인 경우(본문에 정답이 없는 경우)\n",
    "    if start_positions[-1] is None:\n",
    "      start_positions[-1] = tokenizer.model_max_length\n",
    "      deleting_list.append(i)\n",
    "\n",
    "    # 종료 인덱스가 비정상인 경우(본문에 정답이 없는 경우)\n",
    "    if end_positions[-1] is None:\n",
    "      end_positions[-1] = tokenizer.model_max_length\n",
    "\n",
    "      if i not in deleting_list:\n",
    "        deleting_list.append(i)\n",
    "\n",
    "  encodings.update({'start_positions' : start_positions, 'end_positions' : end_positions})\n",
    "  return deleting_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KqsfPOG4rdaY"
   },
   "outputs": [],
   "source": [
    "deleting_list_for_train = add_token_position(train_encoding, train_answers)\n",
    "deleting_list_for_test = add_token_position(test_encoding, test_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pJS8NtOVruaV"
   },
   "outputs": [],
   "source": [
    "print('삭제 예정인 훈련 샘플 ;\\n', deleting_list_for_train)\n",
    "print('삭제 예정인 테스트 샘플 :\\n', deleting_list_for_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8T5r73E5r3Qf"
   },
   "outputs": [],
   "source": [
    "print('761번 샘플의 기존 원문 :\\n', train_contexts[761])\n",
    "print('-' * 200)\n",
    "print('761번 샘플의 질문 :\\n', train_questions[761])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PGyk4bZzsSv1"
   },
   "outputs": [],
   "source": [
    "print('761번 샘플의 기존 정답 :', train_answers[761])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ty0t2vUysaFQ"
   },
   "outputs": [],
   "source": [
    "print('761번 샘플 전처리 후 :\\n', tokenizer.decode(train_encoding['input_ids'][761]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sXhwmzU3trbS"
   },
   "source": [
    "##### 슬라이딩 윈도우는 구현이 복잡하고 속도가 느리기 때문에 정답이 잘린 데이터는 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vQZheIc-squb"
   },
   "outputs": [],
   "source": [
    "def delete_samples(encodings, deleting_list):\n",
    "  input_ids = np.delete(np.array(encodings['input_ids']), deleting_list, axis = 0)\n",
    "  attention_masks = np.delete(np.array(encodings['attention_mask']), deleting_list, axis = 0)\n",
    "  start_positions = np.delete(np.array(encodings['start_positions']), deleting_list, axis = 0)\n",
    "  end_positions = np.delete(np.array(encodings['end_positions']), deleting_list, axis = 0)\n",
    "\n",
    "  X_data = [input_ids, attention_masks]\n",
    "  y_data = [start_positions, end_positions]\n",
    "\n",
    "  return X_data, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Ad_KJQtvAJ5"
   },
   "outputs": [],
   "source": [
    "X_train, y_train = delete_samples(train_encoding, deleting_list_for_train)\n",
    "X_test, y_test = delete_samples(test_encoding, deleting_list_for_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "92Q_pI96vVHH"
   },
   "outputs": [],
   "source": [
    "print('-------------삭제전-------------')\n",
    "print('훈련 데이터 샘플의 개수 :', len(train_contexts))\n",
    "print('테스트 데이터 샘플의 개수 :', len(test_contexts))\n",
    "print()\n",
    "\n",
    "print('-------------삭제후-------------')\n",
    "print('훈련 데이터 샘플의 개수 :', len(X_train[0]))\n",
    "print('테스트 데이터 샘플의 개수 ;', len(X_test[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iuJSb3Viw2Up"
   },
   "source": [
    "# BERT를 이용한 Question Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VPXxm7pEwfev"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0jj8LJGwxW9-"
   },
   "outputs": [],
   "source": [
    "class BertForQuestionAnswering(nn.Module):\n",
    "  def __init__(self, model_name):\n",
    "    super(BertForQuestionAnswering, self).__init__()\n",
    "    self.bert = BertModel.from_pretrained(model_name)\n",
    "\n",
    "    # 출력층에서 사용할 뉴런은 2개이며, 각각 시작 인덱스와 종료 인덱스 예측에 사용된다.\n",
    "    self.qa_outputs = nn.Linear(self.bert.config.hidden_size, 2)\n",
    "\n",
    "  def forward(self, input_ids, attention_mask = None):\n",
    "    outputs = self.bert(input_ids, attention_mask = attention_mask)\n",
    "\n",
    "    # BERT의 마지막 층의 모든 토큰들\n",
    "    # outputs[0].shape == (batch_size, 문장 길이, 768)\n",
    "    # 예로 하나의 데이터가 512개의 단어로 구성되어져 있다면 (batch_size, 512, 768)\n",
    "    # 동시에 50개의 데이터를 처리한다면 (50, 512, 768)\n",
    "    sequence_output = outputs[0]\n",
    "\n",
    "    # 사용할 출력층은 총 뉴런 2개 각각 시작 인덱스 예측과 종료 인덱스 예측에 사용된다.\n",
    "    logits = self.qa_outputs(sequence_output)\n",
    "\n",
    "    # 뉴런 2개를 쪼갠다.\n",
    "    start_logits, end_logits = logits.split(1, dim = -1)\n",
    "\n",
    "    start_logits = start_logits.squeeze(-1)\n",
    "    end_logits = end_logits.squeeze(-1)\n",
    "\n",
    "    start_probs = torch.softmax(start_logits, dim = -1)\n",
    "    end_probs = torch.softmax(end_logits, dim = -1)\n",
    "\n",
    "    return start_probs, end_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sZXfEyOa04ia"
   },
   "outputs": [],
   "source": [
    "model = BertForQuestionAnswering('klue/bert-base')\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr = 5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KpmZAV5J1-Kq"
   },
   "outputs": [],
   "source": [
    "def create_dataset(X_data, y_data):\n",
    "\n",
    "  input_ids, attention_masks = X_data\n",
    "  start_positions, end_positions = y_data\n",
    "\n",
    "  input_ids = torch.tensor(input_ids, dtype = torch.long)\n",
    "  attention_masks = torch.tensor(attention_masks, dtype = torch.long)\n",
    "  start_positions = torch.tensor(start_positions, dtype = torch.long)\n",
    "  end_positions = torch.tensor(end_positions, dtype = torch.long)\n",
    "\n",
    "  dataset = TensorDataset(input_ids, attention_masks, start_positions, end_positions)\n",
    "\n",
    "  return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3lfoL0Wk3Xy2"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_data = create_dataset(X_train, y_train)\n",
    "test_data = create_dataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
    "test_loader = DataLoader(test_data, batch_size = batch_size)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qOgM_Ga-4DIW"
   },
   "source": [
    "# 평가 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QaBjQmyS3wkX"
   },
   "outputs": [],
   "source": [
    "def evaluation(model, loader, loss, device):\n",
    "\n",
    "  total_loss = 0.0\n",
    "  model.eval()\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for input_ids, attention_masks, start_positions, end_positions in loader:\n",
    "      input_ids = input_ids.to(device)\n",
    "      attention_masks = attention_masks.to(device)\n",
    "      start_positions = start_positions.to(device)\n",
    "      end_positions = end_positions.to(device)\n",
    "\n",
    "      start_probs, end_probs = model(input_ids, attention_mask = attention_masks)\n",
    "\n",
    "      # 시작 위치와 종료 위치에 대한 손실 계산\n",
    "      loss_start = loss(start_probs, start_positions)\n",
    "      loss_end = loss(end_probs, end_positions)\n",
    "\n",
    "      # 손실의 평균 계산\n",
    "      batch_loss = (loss_start + loss_end) / 2\n",
    "\n",
    "      total_loss += batch_loss.item()\n",
    "\n",
    "  return total_loss / len(loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E6G2mT13BI6X"
   },
   "source": [
    "# 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K2_Cn0l15lbb"
   },
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "  total_loss = 0.0\n",
    "  model.train()\n",
    "\n",
    "  for input_ids, attention_masks, start_positions, end_positions in tqdm(train_loader, total = len(train_loader)):\n",
    "    input_ids = input_ids.to(device)\n",
    "    attention_masks = attention_masks.to(device)\n",
    "    start_positions = start_positions.to(device)\n",
    "    end_positions = end_positions.to(device)\n",
    "\n",
    "    start_probs, end_probs = model(input_ids, attention_mask = attention_masks)\n",
    "\n",
    "    start_loss = loss(start_probs, start_positions)\n",
    "    end_loss = loss(end_probs, end_positions)\n",
    "    batch_loss = (start_loss + end_loss) / 2\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    batch_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    total_loss += batch_loss.item()\n",
    "\n",
    "  avg_loss = total_loss / len(train_loader)\n",
    "  print(f'Epoch : {epoch + 1} | Loss : {avg_loss}')\n",
    "\n",
    "  val_loss = evaluation(model, test_loader, loss, device)\n",
    "  print(f'Epoch : {epoch + 1} | Validation Loss : {val_loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wgx5Hn2WBKGo"
   },
   "source": [
    "# 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4umihr337lqI"
   },
   "outputs": [],
   "source": [
    "def predict(model, input_ids, attention_mask):\n",
    "\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "    start_probs, end_probs = model(input_ids.unsqueeze(0).to(device), attention_mask = attention_mask.unsqueeze(0).to(device))\n",
    "\n",
    "  start_index = torch.argmax(start_probs).item()\n",
    "  end_index = torch.argmax(end_probs).item()\n",
    "\n",
    "  return start_index, end_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YTicr3KBB471"
   },
   "outputs": [],
   "source": [
    "def display_output(test_data, index, tokenizer):\n",
    "\n",
    "  # index번호의 테스트 데이터 샘플을 얻는다\n",
    "  input_ids, attention_mask, start_position, end_position = test_data[index]\n",
    "\n",
    "  # 임의의 index로부터 테스트 데이터의 질문(question), 본문(context), 정답(true_answer)을 추출하는 과정)\n",
    "  # decoded_text는 [CLS] 본문 [SEP] 질문 [SEP]의 형태로 구성된 텍스트.\n",
    "  decoded_text = tokenizer.decode(input_ids)\n",
    "\n",
    "  # decoded_text로 부터 정답 문자열 추출.\n",
    "  true_answer = toeknizer.decode(input_ids[start_positions : end_positions + 1])\n",
    "\n",
    "  # 본문과 질문을 추출하여 각각 context, question에 저장.\n",
    "  context = decoded_text.split('[SEP]')[0].replace('[CLS]', '').strip()\n",
    "  question = decoded_text.split('[SEP]')[1].strip()\n",
    "\n",
    "  start_index, end_index = predict(model, input_ids, attention_mask)\n",
    "  predicted_answer = tokenizer.decode(input_ids[start_index : end_index + 1])\n",
    "\n",
    "  print(f'본문 : {context}')\n",
    "  print(f'질문 : {question}')\n",
    "  print(f'정답 : {true_answer}')\n",
    "  print(f'예측 : {predicted_answer}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hlI-y0A9FaWg"
   },
   "outputs": [],
   "source": [
    "display_output(test_data, 15, tokenizer)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMmFpnmQYrEST+b0awS/OBm",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
