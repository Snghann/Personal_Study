{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24834,
     "status": "ok",
     "timestamp": 1751601971174,
     "user": {
      "displayName": "김성한",
      "userId": "01456461380721472549"
     },
     "user_tz": -540
    },
    "id": "1FK06_oaE-Py",
    "outputId": "9236c5b3-25c5-4e55-fb01-b9c5fee8e5ac"
   },
   "outputs": [],
   "source": [
    "!pip install konlpy\n",
    "!pip install rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21049,
     "status": "ok",
     "timestamp": 1751601992238,
     "user": {
      "displayName": "김성한",
      "userId": "01456461380721472549"
     },
     "user_tz": -540
    },
    "id": "llES2l3MFSHC",
    "outputId": "f124788d-1e24-440c-c23a-74e4308ac1e5"
   },
   "outputs": [],
   "source": [
    "# 학습 데이터 다운로드\n",
    "!gdown https://drive.google.com/uc?id=13l621lx2nSnXpFpzh78UUEyds_DAzyn6\n",
    "\n",
    "# 테스트 데이터 다운로드\n",
    "!gdown https://drive.google.com/uc?id=10LwhiPlgjOZbtF0Bv5395wYIm23y_QfT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OtCScJFVFgBc"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 43030,
     "status": "ok",
     "timestamp": 1751602035973,
     "user": {
      "displayName": "김성한",
      "userId": "01456461380721472549"
     },
     "user_tz": -540
    },
    "id": "RvhSnIeaFXv-",
    "outputId": "ad93eb78-5668-4aa8-e370-d2b82059eeee"
   },
   "outputs": [],
   "source": [
    "train = pd.read_json('summ_train.json')\n",
    "train = train.dropna()\n",
    "train = train[:20000]\n",
    "\n",
    "test = pd.read_json('summ_test.json')\n",
    "test = test.dropna()\n",
    "test = test[:3000]\n",
    "\n",
    "print(len(train))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 48,
     "status": "ok",
     "timestamp": 1751602036033,
     "user": {
      "displayName": "김성한",
      "userId": "01456461380721472549"
     },
     "user_tz": -540
    },
    "id": "OBxEOiE1GDmM",
    "outputId": "e86656cc-94d0-4619-b755-edcae2f5a8cc"
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 148,
     "status": "ok",
     "timestamp": 1751602036174,
     "user": {
      "displayName": "김성한",
      "userId": "01456461380721472549"
     },
     "user_tz": -540
    },
    "id": "_ZG2EDxFGEzD",
    "outputId": "3e7b4cc6-e109-47ba-8d65-70adbf3603c4"
   },
   "outputs": [],
   "source": [
    "train['documents'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tmxVx-_4Fx6H"
   },
   "outputs": [],
   "source": [
    "def preprocessing_data(data):\n",
    "  outs = []\n",
    "\n",
    "  for doc in data['documents']:\n",
    "    line = []\n",
    "    line.append(doc['media_name'])\n",
    "    line.append(doc['id'])\n",
    "\n",
    "    para = []\n",
    "    for sent in doc['text']:\n",
    "      for s in sent:\n",
    "        para.append(s['sentence'])\n",
    "\n",
    "    line.append(para)\n",
    "    line.append(doc['abstractive'][0])\n",
    "    line.append(doc['extractive'])\n",
    "\n",
    "    a = doc['extractive']\n",
    "    if a[0] == None or a[1] == None or a[2] == None:\n",
    "      continue\n",
    "\n",
    "    outs.append(line)\n",
    "\n",
    "  outs_df = pd.DataFrame(outs)\n",
    "  outs_df.columns = ['media', 'id', 'article_original', 'abstractive', 'extractive']\n",
    "\n",
    "  return outs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sxwUgGWxHExP"
   },
   "outputs": [],
   "source": [
    "train_data = preprocessing_data(train)\n",
    "test_data = preprocessing_data(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 116,
     "status": "ok",
     "timestamp": 1751602036456,
     "user": {
      "displayName": "김성한",
      "userId": "01456461380721472549"
     },
     "user_tz": -540
    },
    "id": "OHh_snZZHJhN",
    "outputId": "547dd377-2fd3-4ac1-bc61-afeabebb7205"
   },
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pYaBgtFoHOXJ"
   },
   "outputs": [],
   "source": [
    "train_data['news'] = train_data['article_original'].apply(lambda x : ' '.join(x))\n",
    "test_data['news'] = test_data['article_original'].apply(lambda x : ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145
    },
    "executionInfo": {
     "elapsed": 90,
     "status": "ok",
     "timestamp": 1751602036577,
     "user": {
      "displayName": "김성한",
      "userId": "01456461380721472549"
     },
     "user_tz": -540
    },
    "id": "xTbWJMGPHiEH",
    "outputId": "6805460c-f4a0-4869-c902-3894b55de119"
   },
   "outputs": [],
   "source": [
    "train_data['news'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9GHL1HsGHl8x"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BartForConditionalGeneration, PreTrainedTokenizerFast\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MMkg1g-GILTE"
   },
   "outputs": [],
   "source": [
    "class KoBARTSummaryDataset(Dataset):\n",
    "  def __init__(self, df, tokenizer, max_len, ignore_index = -100):\n",
    "    super().__init__()\n",
    "    self.tokenizer = tokenizer\n",
    "    self.max_len = max_len\n",
    "    self.docs = df\n",
    "    self.len = self.docs.shape[0]\n",
    "\n",
    "    self.pad_index = self.tokenizer.pad_token_id\n",
    "    self.ignore_index = ignore_index\n",
    "\n",
    "  def add_padding_data(self, inputs):\n",
    "    if len(inputs) < self.max_len:\n",
    "      pad = np.array([self.pad_index] * (self.max_len - len(inputs)))\n",
    "      inputs = np.concatenate([inputs, pad])\n",
    "    else:\n",
    "      inputs = inputs[:self.max_len]\n",
    "\n",
    "    return inputs\n",
    "\n",
    "  def add_ignore_data(self, inputs):\n",
    "    if len(inputs) < self.max_len:\n",
    "      pad = np.array([self.ignore_index] * (self.max_len - len(inputs)))\n",
    "      inputs = np.concatenate([inputs, pad])\n",
    "    else:\n",
    "      inputs = inputs[:self.max_len]\n",
    "\n",
    "    return inputs\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    instance = self.docs.iloc[idx]\n",
    "    input_ids = self.tokenizer.encode(instance['news'])\n",
    "    input_ids = self.add_padding_data(input_ids)\n",
    "\n",
    "    label_ids = self.tokenizer.encode(instance['abstractive'])\n",
    "    label_ids.append(self.tokenizer.eos_token_id)\n",
    "\n",
    "    dec_input_ids = [self.tokenizer.eos_token_id]\n",
    "    dec_input_ids += label_ids[:-1]\n",
    "    dec_input_ids = self.add_padding_data(dec_input_ids)\n",
    "\n",
    "    label_ids = self.add_ignore_data(label_ids)\n",
    "\n",
    "    return {'input_ids' : np.array(input_ids, dtype = np.int_),\n",
    "            'decoder_input_ids' : np.array(dec_input_ids, dtype = np.int_),\n",
    "            'labels' : np.array(label_ids, dtype = np.int_)}\n",
    "\n",
    "  def __len__(self):\n",
    "    return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wgRLSqpyNB9P"
   },
   "outputs": [],
   "source": [
    "class KoBartConditionalGeneration(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(KoBartConditionalGeneration, self).__init__()\n",
    "    self.model = BartForConditionalGeneration.from_pretrained('gogamza/kobart-base-v1')\n",
    "    self.tokenizer = PreTrainedTokenizerFast.from_pretrained('gogamza/kobart-base-v1')\n",
    "    self.pad_token_id = self.tokenizer.pad_token_id\n",
    "\n",
    "  def forward(self, inputs):\n",
    "    attention_mask = inputs['input_ids'].ne(self.pad_token_id).float()\n",
    "    decoder_attention_mask = inputs['decoder_input_ids'].ne(self.pad_token_id).float()\n",
    "\n",
    "    return self.model(input_ids = inputs['input_ids'],\n",
    "                      attention_mask = attention_mask,\n",
    "                      decoder_input_ids = inputs['decoder_input_ids'],\n",
    "                      decoder_attention_mask = decoder_attention_mask,\n",
    "                      labels = inputs['labels'], return_dict = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pGzsooixPDkg"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "6d1800c51a6943c3929dc4e30bf008b9",
      "f8db0dbe1edf4c3cb10f89e50d34f93c",
      "d05879134e9e4100be4fb9f9f281827f",
      "9a61a273929a41458c7d1dd8e45657c9",
      "c96303b265304a818b112c09482fb9b0",
      "e784eab5606e4976bf26019c6f0e71ab",
      "9ca9c3635d51455d9df179f3b04eaf72",
      "567d0542641046cfb9c592891b42a586",
      "99462e24faf14c27bc3adae4cb6733cf",
      "27c5d464c0bf4a0aa25175a170da0f3c",
      "db8ca53b09b7408db6386b896e438fa6",
      "a9494a6899d8496581114ba1f9852bea",
      "7819fb44e6d946c996fd275325eda07e",
      "c423d7b81c6244bebf43e69aaff61292",
      "ab32514c1e34432b9706d9900e06006b",
      "11b6f6657e7442659d03e46619e4c31f",
      "e1ed79067a524ce1ada58ce28183efbf",
      "a973cdf1cf5b46bf9a9eb660ec3eed8a",
      "a931d598036d405fa9e97510c3474682",
      "dfa67b93d7bc4c69a9a53b8966b43c55",
      "a625af0b02df45828a05264a5ed43408",
      "3c7235b2b4ba440fb3a29c4516f24d05",
      "69a0aa7acc1c47afb230459c4c384bb3",
      "d8aa948ecd464181a2347e6d03a038e0",
      "cc2c0185e6154c27a4bfe7559431ea22",
      "2847f5c10e104c7ca3e5f7a32749a6ee",
      "11ce5f54c5bd4236be19c05e896bae7d",
      "4d3b4b8a86dd46caa461e433492cf2a5",
      "e194071fbdbb43efa84e41b832cf29ce",
      "5c1627c388f34b6299e93280b979abd1",
      "3ef0d6c29d364909b546f32f1d99e08e",
      "a72e3c3a377a462f8ec4fddec01e5a67",
      "106a77fb64ac4ac5b8a769dca32271fb",
      "f9f7d42b4a864827a3b4505e08437ecc",
      "cf12d164d37044a6872e1ab41f92b972",
      "2335c446cc504fabb795371d00e90da0",
      "874e1e5d12a9487586279935666f2c1b",
      "4f4116423ce7405fa1302ef4cc0deb41",
      "fb88a87d60f74b6fbb7eee13ac5507d2",
      "20dfff1799bd48adbb2c7f5936d0ab36",
      "9b0883dcb8cb40a8ad793a8ea17cc993",
      "db1d81a483cb4667acb8d6b09d872a3d",
      "19228ce996214c31b6b487984cfecfd4",
      "ba0949752d894dae9652f3ee72826b87",
      "cc1fa4c612f047d28a530baf7bab0488",
      "e5f894bee9be4c6fbe37d3c9132b8e72",
      "bdf45599c3b0460196e896e176062705",
      "6c6a2baa89ff49da838441aaf697864c",
      "84aa25dc853d446685f9a0667807b143",
      "4d6e8d1a393a453c9d74a10cead51319",
      "a585f46ce32d47df8e829369aff8abc3",
      "e11ec60c3fcd4eef96a4b90aa3a06dbc",
      "0aee4227c9fa4411980deeeeeb4495c4",
      "fd302ea2d42747c290e39001b906827f",
      "555a787104f94f58b03319f47945500e"
     ]
    },
    "executionInfo": {
     "elapsed": 5838,
     "status": "ok",
     "timestamp": 1751602061192,
     "user": {
      "displayName": "김성한",
      "userId": "01456461380721472549"
     },
     "user_tz": -540
    },
    "id": "4VTcUZ9RPJv_",
    "outputId": "31712084-319f-452d-d50e-4a4a56717f87"
   },
   "outputs": [],
   "source": [
    "tokenizer = PreTrainedTokenizerFast.from_pretrained('gogamza/kobart-base-v1')\n",
    "model = KoBartConditionalGeneration()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VfF8FszsPTA1"
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "max_len = 512\n",
    "num_workers = 4\n",
    "lr = 3e-5\n",
    "max_epochs = 10\n",
    "warmup_ratio = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1751602061257,
     "user": {
      "displayName": "김성한",
      "userId": "01456461380721472549"
     },
     "user_tz": -540
    },
    "id": "RmdtuwzAPeD7",
    "outputId": "57cbad46-5bf1-4475-fd73-0e14808088f2"
   },
   "outputs": [],
   "source": [
    "train_data = KoBARTSummaryDataset(train_data, tokenizer, max_len)\n",
    "test_data = KoBARTSummaryDataset(test_data, tokenizer, max_len)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size = batch_size, num_workers = num_workers, shuffle = True)\n",
    "test_loader = DataLoader(test_data, batch_size = batch_size, num_workers = num_workers, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vdIyQTDAQWJU"
   },
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr = lr)\n",
    "total_steps = len(train_loader) * max_epochs\n",
    "scheduler = CosineAnnealingWarmRestarts(optimizer, T_0 = int(total_steps * warmup_ratio), T_mult = 1, eta_min = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o8Buni6DRMSG",
    "outputId": "aad5694a-cd34-4baa-82de-cf213c0bb58e"
   },
   "outputs": [],
   "source": [
    "best_loss = np.inf\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "  print(epoch + 1, '수행 중')\n",
    "  model.train()\n",
    "\n",
    "  for batch in tqdm(train_loader, total = len(train_loader)):\n",
    "    batch = {k : v.to(device) for k, v in batch.items()}\n",
    "\n",
    "    outputs = model(batch)\n",
    "    loss = outputs.loss\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "  model.eval()\n",
    "  total_loss = 0.0\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, total = len(test_loader)):\n",
    "      batch = {k : v.to(device) for k, v in batch.items()}\n",
    "\n",
    "      outputs = model(batch)\n",
    "      loss = outputs.loss\n",
    "      total_loss += loss.item()\n",
    "\n",
    "  avg_loss = total_loss / len(test_loader)\n",
    "  print(f'Epoch : {epoch + 1}, Loss : {avg_loss}')\n",
    "\n",
    "  if avg_loss < best_loss:\n",
    "    print(f'Validation loss improved from {best_loss:.4f} to {avg_loss:.4f}.체크포인트를 저장합니다.')\n",
    "    best_loss = avg_loss\n",
    "    torch.save(model.state_dict(), 'best_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "di2ACV0VUBaX"
   },
   "outputs": [],
   "source": [
    "# 모델 인스턴스 생성\n",
    "model_wrapper = KoBARTConditionalGeneration().to(device)\n",
    "\n",
    "# 가중치 로드\n",
    "model_wrapper.load_state_dict(torch.load('best_model.pt'))\n",
    "\n",
    "# 모델을 평가 모드로 설정\n",
    "model_wrapper.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9E7Fo0JJaE0n"
   },
   "outputs": [],
   "source": [
    "output = model_wrapper.model.generate(input_ids, eos_token_id=1, max_length=512,num_beams = 5)\n",
    "output = tokenizer.decode(output[0],skip_special_tokens=True)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7E4CNJD5YDPz"
   },
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "from rouge import Rouge\n",
    "\n",
    "def calculate_rouge(reference_sentence, hypothesis_sentence):\n",
    "  okt = Okt()\n",
    "\n",
    "  def tokenize_and_concat(text):\n",
    "    return ' '.join(otk.morphs(text))\n",
    "\n",
    "  tokenize_reference = tokenize_and_concat(reference_sentence)\n",
    "  tokenize_hypothesis = tokenize_and_concat(hypothesis_sentence)\n",
    "\n",
    "  rouge = Rouge()\n",
    "  scores = rouge.get_scores(tokenize_reference, tokenize_hypothesis)\n",
    "  return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AjrTwDaOZMsP"
   },
   "outputs": [],
   "source": [
    "# 사용 예시\n",
    "label= \"고양이가매트위에앉아있다.\"\n",
    "model1_prediction= \"매트위에고양이가앉아있다.\"\n",
    "model2_prediction= \"고양이가매트위에앉아있다.\"\n",
    "\n",
    "rouge_scores = calculate_rouge(label, model1_prediction)\n",
    "print(rouge_scores[0]['rouge-l']['f'])\n",
    "\n",
    "rouge_scores = calculate_rouge(label, model2_prediction)\n",
    "print(rouge_scores[0]['rouge-l']['f'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AbG1hmwhZmIF"
   },
   "outputs": [],
   "source": [
    "output = '배우 배수지가 매니지먼트 숲과 전속계약을 체결해 배우 배수지의 장점과 매력을 극대화할 수 있는 작품 선택부터 국내외 활동, 가수로서의 솔로 활동까지 활발하게 이루어질 수 있도록 지원할 예정이다.'\n",
    "label = test_data.loc[25]['abstractive']\n",
    "rouge_scores = calculate_rouge(label, output)\n",
    "\n",
    "print('모델의 예측 :', output)\n",
    "print('정답 문장 :', label)\n",
    "print('Rouge Scores :', rouge_scores[0]['rouge-l']['f'])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM1++jjRyFHtzwRpb4AQPh5",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
