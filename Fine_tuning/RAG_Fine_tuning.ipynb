{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E19-a8Jb2I3E"
   },
   "outputs": [],
   "source": [
    "system_message = \"\"\"당신은 검색 결과를 바탕으로 질문에 답변해야 합니다.\n",
    "\n",
    "다음의 지시사항을 따르십시오.\n",
    "\n",
    "1. 질문과 검색 결과를 바탕으로 답변하십시오.\n",
    "2. 검색 결과에 없는 내용을 답변하려고 하지 마십시오.\n",
    "3. 질문에 대한 답이 검색 결과에 없다면 검색 결과에는 \"해당 질문 ~에 대한 내용이 없습니다.\"ㅁ라고 답변하십시오.\n",
    "4. 답변할 때 특정 문서를 참고하여 문장 또는 문단을 작성했다면 뒤에 출처는 이중 리스트로 해당 문서 번호를 남기십시오.\n",
    "예를 들어서 특정 문장이나 문단을 1번 문서에서 인용했다면 뒤에 [[ref11]]이라고 기재하십시오.\n",
    "5. 예를 들어서 특정 문장이나 문단을 1번 문서와 5번 문서에서 동시에 인용했다면 뒤에 [[ref1]], [[ref5]]이라고 기재하십시오.\n",
    "6. 최대한 다수의 문서를 인용하여 답변하십시오.\n",
    "\n",
    "검색 결과 :\n",
    "----\n",
    "{search_result}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11944,
     "status": "ok",
     "timestamp": 1752498073204,
     "user": {
      "displayName": "김성한",
      "userId": "01456461380721472549"
     },
     "user_tz": -540
    },
    "id": "HEkDVYui3CFS",
    "outputId": "777b1703-cfb2-406e-d8c5-a671c4bf4d1d"
   },
   "outputs": [],
   "source": [
    "!pip install torch==2.4.0 transformers==4.45.1 datasets==3.0.1 accelerate==0.34.2 trl==0.11.1 peft==0.13.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NTQFCpHO53Fu"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import LoraConfig\n",
    "from trl import SFTConfig, SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zm8reERm-cq4"
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"iamjoon/klue-mrc-ko-rag-dataset\", split = \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1752499204741,
     "user": {
      "displayName": "김성한",
      "userId": "01456461380721472549"
     },
     "user_tz": -540
    },
    "id": "BPePf-yUF4wZ",
    "outputId": "fa962a5c-144d-4b7f-e452-e5dbf10b2a9e"
   },
   "outputs": [],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 55,
     "status": "ok",
     "timestamp": 1752499347849,
     "user": {
      "displayName": "김성한",
      "userId": "01456461380721472549"
     },
     "user_tz": -540
    },
    "id": "of8LzQj-F7GI",
    "outputId": "c9278596-69fe-4ef9-f026-2ea6ed431ab0"
   },
   "outputs": [],
   "source": [
    "print(\"원본 데이터의 type 분포 :\")\n",
    "for type_name in set(dataset[\"type\"]):\n",
    "    print(f\"{type_name} : {dataset['type'].count(type_name)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QXlon5RPGXo_"
   },
   "outputs": [],
   "source": [
    "ratio = 0.8\n",
    "train_data = []\n",
    "test_data = []\n",
    "\n",
    "for type_name in set(dataset[\"type\"]):\n",
    "    curr_type = [i for i in range(len(dataset)) if dataset[i][\"type\"] == type_name]\n",
    "\n",
    "    test_size = int(len(curr_type) * ratio)\n",
    "\n",
    "    train_data.extend(curr_type[:test_size])\n",
    "    test_data.extend(curr_type[test_size:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1752499647416,
     "user": {
      "displayName": "김성한",
      "userId": "01456461380721472549"
     },
     "user_tz": -540
    },
    "id": "dE-CBprkHW7j",
    "outputId": "282d1037-fd70-459d-e1f9-6741f469a3de"
   },
   "outputs": [],
   "source": [
    "print(len(train_data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1752499681378,
     "user": {
      "displayName": "김성한",
      "userId": "01456461380721472549"
     },
     "user_tz": -540
    },
    "id": "7N21omu-Ht4X",
    "outputId": "d8dbc67f-c4f1-4b1d-abdc-099431d7e4c9"
   },
   "outputs": [],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s51L1e-THZv6"
   },
   "outputs": [],
   "source": [
    "def format_data(sample):\n",
    "    search_result = \"\\n-----\\n\".join([f\"문서 {idx + 1} : {result}\" for idx, result in enumerate(sample[\"search_result\"])])\n",
    "\n",
    "    return {\n",
    "        \"messages\" : [\n",
    "            {\"role\" : \"system\", \"content\" : system_message.format(search_result = search_result)},\n",
    "            {\"role\" : \"user\", \"content\" : sample[\"question\"]},\n",
    "            {\"role\" : \"assistant\", \"content\" : sample[\"answer\"]}\n",
    "        ]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QLojHPdbIrJi"
   },
   "outputs": [],
   "source": [
    "train_dataset = [format_data(dataset[i]) for i in train_data]\n",
    "test_dataset = [format_data(dataset[i]) for i in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1752499981220,
     "user": {
      "displayName": "김성한",
      "userId": "01456461380721472549"
     },
     "user_tz": -540
    },
    "id": "lnCwcXoyI0Xt",
    "outputId": "8bff023e-5b35-453e-e543-e764cf2a8d30"
   },
   "outputs": [],
   "source": [
    "print(type(train_dataset))\n",
    "print(type(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 711,
     "status": "ok",
     "timestamp": 1752500024051,
     "user": {
      "displayName": "김성한",
      "userId": "01456461380721472549"
     },
     "user_tz": -540
    },
    "id": "EuwclE51I3iy",
    "outputId": "6763fc04-5657-42f5-b788-0ffa8dfdf548"
   },
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_list(train_dataset)\n",
    "test_dataset = Dataset.from_list(test_dataset)\n",
    "\n",
    "print(type(train_dataset))\n",
    "print(type(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323,
     "referenced_widgets": [
      "267d46090b0d4ea78957e8e1f8a2d01b",
      "03a8e2ef55294ee5afe3bf640f7714e8",
      "d6c88ab304844371a4aefd2cb89dc1da",
      "03818a49048a496cbac22fdb25689ec6",
      "fb76519fb52142b9a85ee0d80eb4db1e",
      "1883725c15ec4b8c9c6b00cacd715f12",
      "0f92d7efa1f24c5c8d8aead5baa85a7b",
      "f0099c5f360e40548b17765cacafce49",
      "f7f0dfcd20914d0ab91ef8bc8dce987d",
      "64f8e2df41904abf8647a6c36683a823",
      "0be5fdbbc507462d986563c93a4bd8bb",
      "26106f7549484e24a3c765224f6361eb",
      "93f624fabad9464d9fdc3e84d1978429",
      "232a5b6845b54b2facfc91ca598c1b17",
      "4e43bd6fdc974d51be28b8cee7bd7efa",
      "a913fc0e49244d58b718b5c7f55f403f",
      "ad6a8a0ecf234407a42c686d37b8ddba",
      "6e0d2e26ef8f41de871246cf1acc5b10",
      "c586f122478143baa1c154f179fc4501",
      "63553544c9324304aef624ee6f27f7b4",
      "a6b292aadb9c4f1fbd3c6f25d9ece290",
      "1772556a7082471aa45feda3c8a4e9be",
      "16d1a0026a2f4405b8fc4366dc3d2a8d",
      "706b0af123c64c9bbb63fa1e817684ab",
      "9bef6d2a58bc4a078de09e9700d2d26f",
      "6e1f5b9e8a3a4cbca4abfb5a213c85ed",
      "a88be176e32b4fc5ad2f4324b00ea0af",
      "b5f3af18bccf40e1933fda9fc78d191b",
      "81efee927ead43e2a92adb75748d0717",
      "3e06ca69323049fcab020614e53e76e4",
      "e7a10bf4c2cc4de39589adc7da61ff21",
      "6a9e1ad6491445bca81cb768efd4d4a9",
      "db5525415f024d2391f3cb065ecf77e4",
      "87bfdb8f53524e8ab8de808ac258fdae",
      "e416dcee119f4d21988c4f6533dae290",
      "331ea0f8234b4edbac2356dbf13d31ec",
      "b80c41f06c7245dd8760e8109ae50faa",
      "9232432a49354f74a24af02b1d0060ed",
      "f81c7b9493e74da6ac225e080fbf822c",
      "ba12faa2d0154443ac6286f1468070b0",
      "b5a3caff3eb14f3193b9cace5bed47b7",
      "95f2b2625528463ca4d6c9d74b61d3c2",
      "bf2d1097d5bc48dfa665f54cad19879e",
      "2414632af93b4da5b46cdc46313170fe",
      "b88ee31349e74a92bae707ea7c935cb7",
      "a7c26280af4142e8b7188e305b811e8b",
      "f562ead50f1149f691a86b369407f79d",
      "7d4f1b96756943948450bba68ebaff34",
      "7d2a315020f94313b772332e5225ec7f",
      "cd787389ecf541328eb768629efb7454",
      "b603af8c99844141be2bfbcc83795351",
      "4b5ef4ef4ed14d658dbdf69d4c57bc9f",
      "02cc58d136204392984b14a7e89f391f",
      "6dbd534d9d6648338263694220b46b6c",
      "53ec87f313e743c8a5bfecee68910bcd",
      "0940d1b2ead74dc29ebaaa3c7b3250b2",
      "e6564fce0c1d4255946aee2d9c64f883",
      "26ace67091514043af428c4add0151d9",
      "0cbb26bd44d64df28677457991140835",
      "bddd2fadefb741ee9218950ecef56e65",
      "8f98cbd15f1049eea5e0656fc6a447c6",
      "f0e7403f35d046398fb374c9da904094",
      "1ed78f6cf44441fd9b94144306c360b7",
      "e33b57ce01c24f5aabfcb9b2b77d1702",
      "69f802e80f0749088b8ed171d9a82137",
      "52d976a80b5b4846a7070bf1f573a027",
      "b8f8164eda8e47af9b961c36451ae68d",
      "66ede6402fd64c83b0eeee7112924522",
      "1107ca7f179b47f2ab6c97b4c94430ac",
      "36abfa7e7c2543c4b86aee285ee0b458",
      "63c24c404a8143708c5d049dd4df1983",
      "0ce880fa08514ec39e9eb11af4f5b39f",
      "dcd66a668ffa420ca918da5f149b8b40",
      "fc421e2f0e9047718d923adfe2bef699",
      "0a34435d1c2d492a911be5d71da80f7a",
      "dfe543d98552400ca5b816fbc2edbd78",
      "ff47ac96976d4d24a50e765cf976a5c9",
      "2d7635ebe9774226abd3162f530a60f4",
      "2e47f44c5cca4bff8dcc3f49617c1a4d",
      "89d8a060099942d8bab4f52de51f7174",
      "1cf051cced5e466999bdf3e8284d38df",
      "b87e1f87627f46a0a0892f6e474b7f0a",
      "54d95844309e40008adc410383164c4b",
      "47ad6f8eefee48079748b65c357c28fc",
      "da12f46c1ca24477a97147f39cdd11e4",
      "4ecbf3399cc94c8e8115541231effaf5",
      "7a701db8734d4196ba0fe66b8c3c2734",
      "97e26ae2949240749c65ed948589003d",
      "50e83087f14a4d56b184fc67c05f0b59",
      "44cde73e28e24bb18714f1d517247243",
      "51502ec0f1b04c01894f8feb9907b386",
      "2a2ef951f6df42cd97f46d83cc19e319",
      "de6d99a8ab0c4ecaaeef097acebbb45b",
      "50fe3425d1a642e1bdf92fa4a22c2620",
      "2451e652bf8544a0b899541ddeab9e47",
      "3c2feed44d0e4a6cae686d47560aaa66",
      "f66a848ab2ba4c3e994de6703abe94a6",
      "0aa09fa715024a67884af5c328c162fa",
      "79efdec0688d4770883ae7ed40e546c8"
     ]
    },
    "executionInfo": {
     "elapsed": 217791,
     "status": "ok",
     "timestamp": 1752500309523,
     "user": {
      "displayName": "김성한",
      "userId": "01456461380721472549"
     },
     "user_tz": -540
    },
    "id": "XJN0ymNbJC7C",
    "outputId": "2b52118f-7faa-4e4d-e487-a1bb1b46bf2e"
   },
   "outputs": [],
   "source": [
    "model_name = \"Qwen/Qwen2-7B-Instruct\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name,\n",
    "                                             device_map = \"auto\",\n",
    "                                             torch_dtype = torch.bfloat16)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aPT2TJXxJTo5"
   },
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    lora_alpha = 32,\n",
    "    lora_dropout = 0.1,\n",
    "    r = 8,\n",
    "    bias = \"none\",\n",
    "    target_modules = [\"q_proj\", \"v_proj\"],\n",
    "    task_type = \"CAUSAL_LM\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Te9Gf73JJmGI"
   },
   "outputs": [],
   "source": [
    "args = SFTConfig(\n",
    "    output_dir = \"qwen2-7b-rag-ko\",\n",
    "    num_train_epochs = 3,\n",
    "    per_device_train_batch_size = 2,\n",
    "    gradient_accumulation_steps = 2,\n",
    "    gradient_checkpointing = True,\n",
    "    optim = \"adamw_torch_fused\",\n",
    "    logging_steps = 10,\n",
    "    save_strategy = \"steps\",\n",
    "    save_steps = 50,\n",
    "    bf16 = True,\n",
    "    learning_rate = 1e-4,\n",
    "    max_grad_norm = 0.3,\n",
    "    warmup_ratio = 0.03,\n",
    "    lr_scheduler_type = \"constant\",\n",
    "    push_to_hub = False,\n",
    "    remove_unused_columns = False,\n",
    "    dataset_kwargs = {\"skip_prepare_dataset\" : True},\n",
    "    report_to = None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CvtYXs2CKejA"
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    new_batch = {\n",
    "        \"input_ids\" : [],\n",
    "        \"attention_mask\" : [],\n",
    "        \"labels\" : []\n",
    "    }\n",
    "\n",
    "    for example in batch:\n",
    "        clean_messages = []\n",
    "\n",
    "        for mag in example[\"messages\"]:\n",
    "            clean_message = {\n",
    "                \"role\" : msg[\"role\"],\n",
    "                \"content\" : msg[\"content\"]\n",
    "            }\n",
    "            clean_messages.append(clean_message)\n",
    "\n",
    "        text = tokenizer.apply_chat_template(\n",
    "            clean_messages,\n",
    "            tokenize = False,\n",
    "            add_generation_prompt = False\n",
    "        ).strip()\n",
    "\n",
    "        tokenized = tokenizer(\n",
    "            text,\n",
    "            truncation = True,\n",
    "            max_length = max_seq_length,\n",
    "            padding = False,\n",
    "            return_tensors = None\n",
    "        )\n",
    "\n",
    "        input_ids = tokenized[\"input_ids\"]\n",
    "        attention_mask = tokenized[\"attention_mask\"]\n",
    "        labels = [-100] * len(input_ids)\n",
    "\n",
    "        im_start = \"<|im_start|>\"\n",
    "        im_end = \"<|im_end|>\"\n",
    "        assistant = \"assistant\"\n",
    "\n",
    "        im_start_token = tokenizer.encode(im_start, add_special_tokens = False)\n",
    "        im_end_token = tokenizer.encode(im_end, add_special_tokens = False)\n",
    "        assistant_token = tokenizer.encode(assistant, add_special_tokens = False)\n",
    "\n",
    "        i = 0\n",
    "        while i <= len(input_ids) - len(im_start_token):\n",
    "            if input_ids[i : i + len(im_start_token)] == im_start_token:\n",
    "\n",
    "                assistant_pos = i + len(im_start_token)\n",
    "                if (assistant_pos <+ len(input_ids) - len(assistant_token)) and (input_ids[assistant_pos : assistant_pos + len(assistant_token)] == assistant_token):\n",
    "\n",
    "                    current_pos = assistant_pos + len(assistant_token)\n",
    "                    while current_pos <= len(input_ids) - len(im_end_token):\n",
    "                        if input_ids[current_pos : current_pos + len(im_end_token)] == im_end_token:\n",
    "                            for j in range(len(im_end_token)):\n",
    "                                labels[current_pos + j] = input_ids[current_token + j]\n",
    "                            break\n",
    "\n",
    "                        labels[current_pos] = input_ids[current_pos]\n",
    "                        current_pos += 1\n",
    "\n",
    "                    i = current_pos\n",
    "\n",
    "            i += 1\n",
    "\n",
    "        new_batch[\"input_ids\"].append(input_ids)\n",
    "        new_batch[\"attention_mask\"].append(attention_mask)\n",
    "        new_batch[\"labels\"].append(labels)\n",
    "\n",
    "    max_length = max(len(ids) for ids in new_batch[\"input_ids\"])\n",
    "    for i in range(len(new_batch[\"input_ids\"])):\n",
    "        pad_len = max_length - len(new_batch[\"input_ids\"][i])\n",
    "        new_batch[\"input_ids\"][i].extend([tokenizer.pad_token_id] * pad_len)\n",
    "        new_batch[\"attention_mask\"][i].extend([0] * pad_len)\n",
    "        new_batch[\"labels\"][i].extend([-100] * pad_len)\n",
    "\n",
    "    for k, v in new_batch.items():\n",
    "        new_batch[k] = torch.tensor(v)\n",
    "\n",
    "    return new_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Rdh6SXGQG3r"
   },
   "outputs": [],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    args = args,\n",
    "    max_seq_length = max_seq_length,\n",
    "    train_dataset = train_dataset,\n",
    "    data_collator = collate_fn,\n",
    "    peft_config = peft_config\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L2KQfCdnQiVQ"
   },
   "outputs": [],
   "source": [
    "prompt_list = []\n",
    "label_list = []\n",
    "\n",
    "for prompt in test_dataset[\"messages\"]:\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        prompt, tokenize = False, add_generation_prompt = False\n",
    "    )\n",
    "    input = text.split(\"<|im_start|>assistant\")[0] + \"<|im_start|>assistant\"\n",
    "    label = text.split(\"<|im_start|>assistant\")[1]\n",
    "\n",
    "    prompt_list.append(input)\n",
    "    label_list.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WO0NkCu8SvH6"
   },
   "outputs": [],
   "source": [
    "def test_inference(pipe, prompt):\n",
    "    outputs = pipe(prompt, max_new_tokens = 1024, eos_token_id = eos_token, do_sample = False)\n",
    "    return outputs[0][\"generated_text\"][len(prompt) : ].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rxftVToTSUl-"
   },
   "outputs": [],
   "source": [
    "base_model_name = \"Qwen/Qwen2-7B-Instruct\"\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_name,\n",
    "    device_map = \"auto\",\n",
    "    torch_dtype = torch.bfloat16\n",
    ")\n",
    "\n",
    "base_pipe = pipeline(\"text-generation\", model = base_model, tokenizer = tokenizer)\n",
    "eos_token = tokenizer(\"<|im_end|>\", add_special_tokens = False)[\"input_ids\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XPfaYOeST-Nb"
   },
   "outputs": [],
   "source": [
    "base_prompt = prompt_list[42]\n",
    "base_label = label_list[42]\n",
    "\n",
    "print(f\"모델의 예측 : \\n {test_inference(base_pipe, base_prompt)}\")\n",
    "print(f\"정답 : \\n {base_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gtslqs9QRq9G"
   },
   "outputs": [],
   "source": [
    "peft_model_name = \"qwen2-7b-rag-ko/checkpoint-285\"\n",
    "\n",
    "peft_model = AutoModelForCausalLM.from_pretrained(\n",
    "    peft_model_name,\n",
    "    device_map = \"auto\",\n",
    "    torch_dtype = torch.bfloat16\n",
    ")\n",
    "\n",
    "peft_pipe = pipeline(\"text-generation\", model = peft_model, tokenizer = tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "grnEhRe0SI8M"
   },
   "outputs": [],
   "source": [
    "peft_prompt = prompt_list[42]\n",
    "peft_label = label_list[42]\n",
    "\n",
    "print(f\"모델의 예측 : \\n {test_inference(peft_pipe, peft_prompt)}\")\n",
    "print(f\"정답 : \\n {peft_label}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN27yiCtesbEggToJcOp5U1",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
